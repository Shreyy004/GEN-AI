{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Statement\n",
        "Create a chain that performs the following tasks:\n",
        "\n",
        "1. Identifies the sentiment of a given text.\n",
        "2. Based on the sentiment, generates a follow-up question. If the sentiment is positive, the follow-up question will be related to what made it positive; if negative, the follow-up question will be about what made it negative."
      ],
      "metadata": {
        "id": "ceAYSOTSl8R5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hints and Instructions"
      ],
      "metadata": {
        "id": "Hjxv_QMCmHw0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Install Required Libraries**:\n",
        "   - Begin by installing the necessary Python libraries using pip, which is the Python package installer. Each `!pip install` command installs a different package:\n",
        "     - `langchain` - A library for building applications using large language models.\n",
        "     - `openai` - The official Python library for interacting with OpenAI’s APIs, including GPT models.\n",
        "     - `cohere` - A Python library for integrating Cohere's language models into applications.\n",
        "     - `langchain_community` - An additional set of tools or extensions for `langchain` that might be community-driven or experimental.\n",
        "\n",
        "\n",
        "\n",
        "2. **Importing Modules**:\n",
        "   - After installing the packages, import the necessary modules from the `langchain` library along with other Python standard libraries:\n",
        "     - From `langchain`, import `LLMChain`, `SequentialChain`, `Prompt`, `OpenAI`, `Cohere`, and `PromptTemplate`. These are classes and methods used to set up and utilize language model chains and prompts effectively.\n",
        "     - Import the `os` module from Python’s standard library, which will be used to manage environment variables.\n",
        "\n",
        "\n",
        "\n",
        "3. **Set Environment Variables**:\n",
        "   - Set up the environment variable for the Cohere API key. This is crucial for authenticating API requests to Cohere. Replace `\"Your Cohere Key\"` with the actual API key provided to you by Cohere.\n",
        "   - The `os.environ` dictionary in Python is used to set environment variables. Here, you're setting the `'COHERE_API_KEY'` environment variable which the `cohere` library will use to authenticate your requests.\n",
        "\n",
        "\n",
        "Ensure you replace `\"Your Cohere Key\"` with your actual Cohere API key before running the code. Also, make sure you have the appropriate permissions and environment (like Jupyter notebook or a Python script) where system commands like `!pip install` are allowed to execute."
      ],
      "metadata": {
        "id": "PidCB-sCreuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code here"
      ],
      "metadata": {
        "id": "G73WuTwCsjTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install cohere\n",
        "!pip install langchain_community"
      ],
      "metadata": {
        "id": "yXgUkFbhmZG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1371b2b3-126c-49e1-f410-fb1e3cc08c8e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Collecting cohere\n",
            "  Downloading cohere-5.15.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting fastavro<2.0.0,>=1.9.4 (from cohere)\n",
            "  Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: httpx>=0.21.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.28.1)\n",
            "Collecting httpx-sse==0.4.0 (from cohere)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: pydantic>=1.9.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.11.4)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.33.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<1,>=0.15 in /usr/local/lib/python3.11/dist-packages (from cohere) (0.21.1)\n",
            "Collecting types-requests<3.0.0,>=2.0.0 (from cohere)\n",
            "  Downloading types_requests-2.32.0.20250515-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from cohere) (4.13.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.21.2->cohere) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.7.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.9.2->cohere) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->cohere) (2.4.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers<1,>=0.15->cohere) (0.31.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.67.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.21.2->cohere) (1.3.1)\n",
            "Downloading cohere-5.15.0-py3-none-any.whl (259 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading fastavro-1.11.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20250515-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: types-requests, httpx-sse, fastavro, cohere\n",
            "Successfully installed cohere-5.15.0 fastavro-1.11.1 httpx-sse-0.4.0 types-requests-2.32.0.20250515\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.59)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.42)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (2.11.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain_community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain_community) (1.3.1)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain_community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain_community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary modules from LangChain\n",
        "from langchain import LLMChain\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain.prompts import Prompt\n",
        "from langchain.llms import OpenAI, Cohere\n",
        "from langchain import PromptTemplate"
      ],
      "metadata": {
        "id": "36rgTkFXnfm3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ['COHERE_API_KEY'] = userdata.get(\"\")"
      ],
      "metadata": {
        "id": "buvakEZsp3St"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain 1: Define a chain to identify the sentiment of the input text"
      ],
      "metadata": {
        "id": "wUXDYuvso4vH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Initialize the Language Model (LLM)**:\n",
        "   - First, instantiate the Cohere language model. This object, `llm`, will be used to process inputs through the language model's API.\n",
        "   - Ensure that the Cohere library is installed and that you have set up necessary API keys or other configurations as required.\n",
        "\n",
        "2. **Create a Prompt Template**:\n",
        "   - Define a `PromptTemplate` which specifies how the input should be formatted when sent to the language model.\n",
        "   - `input_variables`: This is a list of variables that you expect to dynamically change in your prompt template. In this case, it is [\"text\"], which will be replaced by actual text you want to analyze.\n",
        "   - `template`: This string lays out the text structure sent to the model. It instructs the model to analyze the sentiment of the input text and respond with either 'Positive' or 'Negative'. It incorporates `{text}` as a placeholder that will be replaced with actual text at runtime.\n",
        "\n",
        "\n",
        "3. **Setup the Sentiment Analysis Chain**:\n",
        "   - Create an `LLMChain` object, which uses the `llm` you initialized and the `prompt` you defined.\n",
        "   - `prompt`: This is set to the `sentiment_analysis_prompt` object.\n",
        "   - `output_key`: This parameter specifies which part of the response to focus on or extract. Since the prompt instructs the model to end responses with \"Sentiment:\", this key helps in extracting the actual sentiment value ('Positive' or 'Negative') from the response.\n",
        "\n",
        "\n",
        "4. **Invoke the Chain and Print the Result**:\n",
        "   - Use the `invoke` method on the `sentiment_analysis_chain` object, providing a string of text that you wish to analyze. This is where the sentiment analysis actually happens.\n",
        "   - Print the extracted sentiment. The result will be accessed using the `output_key` specified earlier (\"sentiment\"), which should give either 'Positive' or 'Negative' based on the text analysis.\n"
      ],
      "metadata": {
        "id": "vAkkBNcqrv5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your Code here"
      ],
      "metadata": {
        "id": "vgq8_UuHsgVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "llm=Cohere()\n",
        "\n",
        "sentiment_analysis_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"\"\"Analyze the sentiment of the following text.\n",
        "    Respond with 'Positive' or 'Negative':\\n\\n{text}\\n\\nSentiment:\"\"\"\n",
        ")\n",
        "\n",
        "sentiment_analysis_chain = LLMChain(llm=llm,\n",
        "                           prompt=sentiment_analysis_prompt,\n",
        "                           output_key=\"sentiment\")\n",
        "\n",
        "\n",
        "result = sentiment_analysis_chain.invoke(input=\"I had an amazing experience with their customer service team! They were incredibly helpful and resolved my issue quickly and efficiently.\")\n",
        "print(result[\"sentiment\"])"
      ],
      "metadata": {
        "id": "Mgt1HnejnyLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e145d84-a587-4f81-89cb-442e3d049f24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-8a7c3994828e>:2: LangChainDeprecationWarning: The class `Cohere` was deprecated in LangChain 0.1.14 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-cohere package and should be used instead. To use it run `pip install -U :class:`~langchain-cohere` and import as `from :class:`~langchain_cohere import Cohere``.\n",
            "  llm=Cohere()\n",
            "<ipython-input-4-8a7c3994828e>:10: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  sentiment_analysis_chain = LLMChain(llm=llm,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Positive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chain 2: Define a chain to generate a follow-up question based on the sentiment"
      ],
      "metadata": {
        "id": "E9VPuq8jo_iU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Initialize the Language Model (LLM)**:\n",
        "   - First, instantiate the Cohere language model. This object, `llm`, will be used to process inputs through the language model's API.\n",
        "   - Make sure that the Cohere library is installed and that you have configured it properly with necessary API keys.\n",
        "\n",
        "2. **Define a Prompt Template**:\n",
        "   - Create a `PromptTemplate` which specifies how to format the input when sending it to the language model.\n",
        "   - `input_variables`: List the variables that will dynamically change in the prompt template. Here, \"sentiment\" is the variable that will be replaced with either 'Positive' or 'Negative'.\n",
        "   - `template`: This string outlines the text structure to send to the model. It provides instructions for generating a follow-up question based on the sentiment ('Positive' or 'Negative'). This template uses conditional language to specify different questions for different sentiments.\n",
        "\n",
        "\n",
        "\n",
        "3. **Setup the Follow-Up Question Chain**:\n",
        "   - Create an `LLMChain` object using the `llm` and `prompt` you defined.\n",
        "   - `prompt`: This is set to the `follow_up_question_prompt` object.\n",
        "   - `output_key`: This parameter specifies which part of the response to extract. In this case, the model is instructed to generate a follow-up question, so the `output_key` is \"follow_up_question\".\n",
        "\n",
        "\n",
        "\n",
        "4. **Invoke the Chain and Print the Result**:\n",
        "   - Use the `invoke` method on the `follow_up_question_chain` object, providing an input that specifies the sentiment (either \"Positive\" or \"Negative\"). This is where the follow-up question generation happens.\n",
        "   - Print the follow-up question extracted. The result will be accessed using the `output_key` specified earlier (\"follow_up_question\").\n"
      ],
      "metadata": {
        "id": "dplYJ8jVszbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code here"
      ],
      "metadata": {
        "id": "dNBZj9Vys8GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm=Cohere()\n",
        "\n",
        "follow_up_question_prompt = PromptTemplate(\n",
        "    input_variables=[\"sentiment\"],\n",
        "    template=\"\"\"\n",
        "    Given the sentiment '{sentiment}', generate a follow-up question:\n",
        "    - If the sentiment is 'Positive', ask what specifically made the experience positive.\n",
        "    - If the sentiment is 'Negative', ask what specifically made the experience negative.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "follow_up_question_chain = LLMChain(llm=llm,\n",
        "                              prompt=follow_up_question_prompt,\n",
        "                              output_key=\"follow_up_question\")\n",
        "\n",
        "result = follow_up_question_chain.invoke(input=\"Positive\")\n",
        "\n",
        "# Print the books\n",
        "print(result['follow_up_question'])\n"
      ],
      "metadata": {
        "id": "uaLyuetpo_Cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a24dd422-4b5d-4d41-af07-cadbb55b135d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Great, thank you for sharing this highlights of your experience in a nutshell. Could you please delve deeper and share some specific aspects, good or bad, that stood out to you the most regarding the food, service, atmosphere, special requests, and so on? \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Combine both chains into a SequentialChain"
      ],
      "metadata": {
        "id": "VBVdXzCMqILm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Define the SequentialChain**:\n",
        "   - **`SequentialChain`**: This is a special type of chain in `langchain` that allows multiple chains to be executed in sequence. Each chain’s output can be used as input for the subsequent chain in the sequence.\n",
        "   - **`chains`**: List the chains that will be run in sequence. Here, `sentiment_analysis_chain` analyzes the sentiment of the text, and `follow_up_question_chain` generates a follow-up question based on the detected sentiment.\n",
        "   - **`input_variables`**: Define the variables that the first chain in the sequence expects. In this case, `[\"text\"]` indicates that the initial input will be plain text.\n",
        "   - **`output_variables`**: Specify the variables that will be output after the last chain has run. Here, `[\"sentiment\", \"follow_up_question\"]` are expected as outputs from the entire sequence.\n",
        "\n",
        "\n",
        "2. **Prepare the Input Text**:\n",
        "   - Define a variable `input_text` containing the text you want to analyze. This example uses a simple statement about having a great time at the park, which is suitable for sentiment analysis.\n",
        "\n",
        "\n",
        "3. **Invoke the SequentialChain**:\n",
        "   - Call the `invoke` method on the `sentiment_chain`, passing a dictionary with the `text` key set to `input_text`. This dictionary matches the `input_variables` defined in the `SequentialChain`.\n",
        "   - The `invoke` method will process the text through both chains sequentially: first analyzing sentiment and then generating a follow-up question.\n",
        "\n",
        "\n",
        "4. **Print the Results**:\n",
        "   - Extract and print the sentiment and follow-up question from the result. The keys used for extraction (`\"sentiment\"` and `\"follow_up_question\"`) match those defined in the `output_variables` of the `SequentialChain`.\n",
        "\n",
        "\n",
        "This setup demonstrates how to seamlessly integrate multiple processing steps (like sentiment analysis and follow-up question generation) using `langchain`. The SequentialChain makes it easy to handle complex workflows where the output of one model feeds into another, providing a powerful tool for building advanced text processing applications."
      ],
      "metadata": {
        "id": "837i7JbJs-sS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your Code here"
      ],
      "metadata": {
        "id": "4TZcTwMatTPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_chain = SequentialChain(\n",
        "    chains=[sentiment_analysis_chain, follow_up_question_chain],\n",
        "    input_variables=[\"text\"],\n",
        "    output_variables=[\"sentiment\", \"follow_up_question\"]\n",
        ")\n",
        "\n",
        "# Example input text\n",
        "input_text = \"I had a great time at the park today. The weather was perfect and I enjoyed a nice picnic.\"\n",
        "\n",
        "# Running the SequentialChain with the input text\n",
        "result = sentiment_chain.invoke({\"text\": input_text})\n",
        "\n",
        "# Print the results\n",
        "print(\"Sentiment:\", result[\"sentiment\"])\n",
        "print(\"Follow-up Question:\", result[\"follow_up_question\"])\n"
      ],
      "metadata": {
        "id": "E5eyvGtWmBVm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b63b83-744b-447a-ad43-b38cf08fbc17"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment:  Positive\n",
            "Follow-up Question: Thanks for the feedback! Could you provide some more details on the positive aspects you mentioned? It would really help us understand your experience and ensure we're delivering the best service possible. If you have any specific examples or feedback on what exceeded your expectations, those would be most helpful! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eWPM8EyLmTl-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}